<?xml version="1.0" encoding="UTF-8" standalone="no"?><configuration>
<property><name>hadoop.proxyuser.hive.groups</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.block.access.token.lifetime</name><value>600</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.application.framework.path</name><value>/hdp/apps/2.6.5.0-292/mapreduce/mapreduce.tar.gz#mr-framework</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.skewjoin.key</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.index.compact.binary.search</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.log.level</name><value>INFO</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.lazypersist.file.scrub.interval.sec</name><value>300</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.admin.user.env</name><value>LD_LIBRARY_PATH=/usr/hdp/2.6.5.0-292/hadoop/lib/native:/usr/hdp/2.6.5.0-292/hadoop/lib/native/Linux-amd64-64:./mr-framework/hadoop/lib/native:./mr-framework/hadoop/lib/native/Linux-amd64-64</value><source>programatically</source><source>job.xml</source></property>
<property><name>file.bytes-per-checksum</name><value>512</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.client.completion.pollinterval</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.internal.ss.authz.settings.applied.marker</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.azure.secure.mode</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.log-aggregation-enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name><value>org.apache.hadoop.mapred.ShuffleHandler</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.edit.log.autoroll.check.interval.ms</name><value>300000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.retry-after-speculate</name><value>15000</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.fallback-to-simple-auth-allowed</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.failover.connection.retries</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.system.dir</name><value>/tmp/hadoop-hive/mapred/system</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.event.db.listener.timetolive</name><value>86400s</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.scheduler.minimum-allocation-mb</name><value>512</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile.map.params</name><value>-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.memory.mb</name><value>512</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.dns.interface</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.transfer.socket.recv.buffer.size</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.log.server.url</name><value>http://ip-10-11-21-11.alationdata.com:19888/jobhistory/logs</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.failed.volumes.tolerated</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.authentication</name><value>NONE</value><source>programatically</source><source>job.xml</source></property>
<property><name>_hive.tmp_table_space</name><value>/tmp/hive/hdfs/f9f9016f-5d22-4202-bfec-0ab6e2519f06/_tmp_space.db</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.metrics.logger.period.seconds</name><value>600</value><source>programatically</source><source>job.xml</source></property>
<property><name>stream.stderr.reporter.prefix</name><value>reporter:</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.slow.io.warning.threshold.ms</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.groups.cache.secs</name><value>300</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.xfs-filter.xframe-options</name><value>SAMEORIGIN</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.env-whitelist</name><value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.top.window.num.buckets</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.authorization.storage.checks</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>map.sort.class</name><value>org.apache.hadoop.util.QuickSort</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.java.opts</name><value>-server -Xmx545m -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseParallelGC -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.safemode.threshold-pct</name><value>0.999</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.jobhistory.task.numberprogresssplits</name><value>12</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.storeManagerType</name><value>rdbms</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.short.circuit.shared.memory.watcher.interrupt.check.ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.s3a.impl</name><value>org.apache.hadoop.fs.s3a.S3A</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.caller.context.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.distcp.privileged.doAs</name><value>hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.max.writer.wait</name><value>5000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3n.block.size</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.client.thread-count</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.read.shortcircuit</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.end-notification.max.retry.interval</name><value>5000</value><source>mapred-default.xml</source></property>
<property><name>hadoop.security.authentication</name><value>simple</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.mmap.retry.timeout.ms</name><value>300000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.custom-extensions.root</name><value>/hdp/ext/2.6/hadoop</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.readahead.bytes</name><value>4194304</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.max-age-ms</name><value>604800000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.client-am.ipc.max-retries</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.followby.map.aggr.hash.percentmemory</name><value>0.3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.script.recordwriter</name><value>org.apache.hadoop.hive.ql.exec.TextRecordWriter</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.multigroupby.singlereducer</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.sleep-delay-before-sigkill.ms</name><value>250</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.execution.reduce.groupby.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.authentication.ldap.guidKey</name><value>uid</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.shell.missing.defaultFs.warning</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.trash.interval</name><value>360</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.max.locked.memory</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.filter.initializers</name><value>org.apache.hadoop.yarn.server.webproxy.amfilter.AmFilterInitializer</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.har.impl</name><value>org.apache.hadoop.hive.shims.HiveHarFileSystem</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.ipc.address</name><value>0.0.0.0:8010</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.delegation.token.renew-interval</name><value>86400000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.address</name><value>ip-10-11-21-11.alationdata.com:8088</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.client.rpc.sasl.mechanisms</name><value>DIGEST-MD5</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.current.database</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.index.groupby</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.max.connections</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.local-cache.max-files-per-directory</name><value>8192</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log-aggregation.num-log-files-per-app</name><value>336</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.replication.work.multiplier.per.iteration</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.mapper.new-api</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.address</name><value>local</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.slow.io.warning.threshold.ms</name><value>300</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.client.max-cached-nodemanagers-proxies</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.working.dir</name><value>hdfs://ip-10-11-21-11.alationdata.com:8020/user/hdfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.instrumentation</name><value>org.apache.hadoop.mapred.TaskTrackerMetricsInst</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.zk.quorum</name><value>ip-10-11-21-11.alationdata.com:2181</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.job.committer.commit-window</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.zk.session.timeout.ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.exec.print.summary</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.heartbeat.recheck-interval</name><value>300000</value><source>programatically</source><source>job.xml</source></property>
<property><name>nfs.exports.allowed.hosts</name><value>* rw</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.filter.hook</name><value>org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.integral.jdo.pushdown</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.util.hash.type</name><value>murmur</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.replication.min</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.user.name</name><value>hdfs</value><source>programatically</source></property>
<property><name>mapreduce.admin.map.child.java.opts</name><value>-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dhdp.version=2.6.5.0-292</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cli.print.current.db</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.debug.localtask</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.authorization.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.warehouse.subdir.inherit.perms</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.retiredjobs.cache.size</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3.client-write-packet-size</name><value>65536</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.scheduler.address</name><value>ip-10-11-21-11.alationdata.com:8030</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.try.direct.sql</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3.block.size</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.filter.user</name><value>(&amp;(objectClass=user)(sAMAccountName={0}))</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.permissions.superusergroup</name><value>hdfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.resource-tracker.address</name><value>ip-10-11-21-11.alationdata.com:8025</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.execution.engine</name><value>mr</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.notification.sequence.lock.max.retries</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.root-dir</name><value>/sharedcache</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.xframe.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>credentialStoreClassPath</name><value>/var/lib/ambari-agent/cred/lib/*</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.script.operator.env.blacklist</name><value>hive.txn.valid.txns,hive.script.operator.env.blacklist</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.long.polling.timeout</name><value>5000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.node-labels.fs-store.retry-policy-spec</name><value>2000, 500</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.bind-host</name><value>0.0.0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.zk-timeout-ms</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>ambari.hive.db.schema.name</name><value>hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.orc.splits.include.file.footer</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.optimized.hashtable.probe.percent</name><value>0.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.http-address</name><value>ip-10-11-21-11.alationdata.com:50070</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds</name><value>3600</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.webapp.rest-csrf.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.async.exec.wait.queue.size</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.client.output.filter</name><value>FAILED</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.memory.limit.percent</name><value>0.25</value><source>programatically</source><source>job.xml</source></property>
<property><name>nfs.rtmax</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.max.full</name><value>0.9</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.default.fileformat</name><value>TextFile</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.ssl.client.conf</name><value>ssl-client.xml</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.ftp.host</name><value>0.0.0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.groupby</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.simple.anonymous.allowed</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>nfs.server.port</name><value>2049</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.write-lock-reporting-threshold-ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.remove.identity.project</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.admin-command-opts</name><value>-Dhdp.version=2.6.5.0-292</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.msck.repair.batch.size</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.ha.log-roll.period</name><value>120</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.kms.client.authentication.retry-count</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.io.sort.factor</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.https.address</name><value>0.0.0.0:50475</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.uploader.server.address</name><value>0.0.0.0:8046</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.limit.query.max.table.partition</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.unlock.numretries</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.job.debug.capture.stacktraces</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hmshandler.retry.interval</name><value>2000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.clear.dangling.scratchdir.interval</name><value>1800s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.reduces</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.recovery.compaction-interval-secs</name><value>3600</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.reduce.tasks.maximum</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.edits.dir</name><value>/hadoop/hdfs/namesecondary</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.cleaner.interval-ms</name><value>86400000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.atomic</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.admin.reduce.child.java.opts</name><value>-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dhdp.version=2.6.5.0-292</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.vmem-check-enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.blobstore.supported.schemes</name><value>s3,s3a,s3n</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern</name><value>^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.replication.considerLoad</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cli.print.header</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.health-monitor.sleep-after-disconnect.ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.txn.heartbeat.threadpool.size</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.counters.max</name><value>130</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.running.reduce.limit</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.webapp.rest-csrf.methods-to-ignore</name><value>GET,OPTIONS,HEAD</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3.blocksize</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.default.partition.name</name><value>__HIVE_DEFAULT_PARTITION__</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapred.partitioner</name><value>org.apache.hadoop.hive.ql.io.DefaultHivePartitioner</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.groupby.mapaggr.checkinterval</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.tasks.sleeptimebeforesigkill</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.classloader</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>serialization.lib</name><value>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.application.classpath</name><value>$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*:/usr/hdp/2.6.5.0-292/hadoop/lib/hadoop-lzo-0.6.0.2.6.5.0-292.jar:/etc/hadoop/conf/secure:/usr/hdp/current/ext/hadoop/*</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.connect.max-wait.ms</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.ha.automatic-failover.embedded</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.map.aggr.hash.min.reduction</name><value>0.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.joblist.cache.size</name><value>20000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.authentication.spnego.keytab</name><value>HTTP/_HOST@EXAMPLE.COM</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile.maps</name><value>0-2</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.short.circuit.replica.stale.threshold.ms</name><value>1800000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.mode.local.auto.input.files.max</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.worker.timeout</name><value>86400L</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.kms.client.encrypted.key.cache.num.refill.threads</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.variable.substitute</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.ssl.server.conf</name><value>ssl-server.xml</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.state-store-class</name><value>org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.test.mode.prefix</name><value>test_</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.dml.events</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.generic-application-history.max-applications</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.full.block.report.lease.length.ms</name><value>300000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.fileinputformat.list-status.num-threads</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.test.mode.samplefreq</name><value>32</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.edits.dir</name><value>/hadoop/hdfs/namenode</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3.bytes-per-checksum</name><value>512</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.authentication.spnego.principal</name><value>/etc/security/keytabs/spnego.service.keytab</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.authorization.storage.check.externaltable.drop</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.version</name><value>1.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.permissions.umask-mode</name><value>022</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.proxy-user-privileges.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.execution.reduce.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.skewjoin.mapjoin.map.tasks</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.rest-csrf.custom-header</name><value>X-XSRF-Header</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.http.policy</name><value>HTTP_ONLY</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.path.based.cache.refresh.interval.ms</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.zk-acl</name><value>world:anyone:rwcda</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.cgroups.mount</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.connect.max.retries.on.timeouts</name><value>45</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.map.groupby.sorted.testmode</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.fuse.connection.timeout</name><value>300</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.adl.impl</name><value>org.apache.hadoop.fs.adl.Adl</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.block.access.key.update.interval</name><value>600</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.token.tracking.ids.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.default.row.index.stride</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.health-monitor.rpc-timeout.ms</name><value>45000</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.azure.authorization.caching.enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.script.recordreader</name><value>org.apache.hadoop.hive.ql.exec.TextRecordReader</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.fail-fast</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.cross-origin.allowed-origins</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.summary-store</name><value>org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.server.max.message.size</name><value>104857600</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.async.exec.keepalive.time</name><value>10s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.client.submit.file.replication</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.dbconnectionstring</name><value>jdbc:derby:;databaseName=TempStatsStore;create=true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.zookeeper.connection.max.retries</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.list.num.entries</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.logging.operation.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.ssl.require.client.cert</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.cache.revocation.timeout.ms</name><value>900000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.login.timeout</name><value>20s</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.ha.tail-edits.period</name><value>60</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.client.nodemanager-connect.retry-interval-ms</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.inotify.max.events.per.rpc</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.rpc.protection</name><value>authentication</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.fs.state-store.uri</name><value> </value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.dynamic.partition</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.scan.period.hours</name><value>504</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.costmodel.hdfs.write</name><value>10.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.block.id.layout.upgrade.threads</name><value>12</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.exec.inplace.progress</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.read.shortcircuit.skip.checksum</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.temporary.table.storage</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cli.pretty.output.num.cols</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.counters.group.name</name><value>HIVE</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.store.in-memory.initial-delay-mins</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.file-block-storage-locations.timeout.millis</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.client.nodemanager-client-async.thread-pool-max-size</name><value>500</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.block.padding.tolerance</name><value>0.05</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.domain.socket.path</name><value>/var/lib/hadoop-hdfs/dn_socket</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.dns.nameserver</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.stale.datanode.interval</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.costmodel.local.fs.write</name><value>4.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.join.cache.size</name><value>25000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.file.max.footer</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.archives.visibilities</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.address</name><value>ip-10-11-21-11.alationdata.com:10200</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.app-submission.cross-platform</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.scheme.class</name><value>dfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.archive.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.http.policy</name><value>HTTP_ONLY</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.output.compress</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.archive.intermediate.original</name><value>_INTERMEDIATE_ORIGINAL</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.xsrf.filter.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.max.threads</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cluster.delegation.token.store.zookeeper.znode</name><value>/hive/cluster/delegation</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.done-dir</name><value>/mr-history/done</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.reducer.class</name><value>org.apache.hadoop.hive.ql.exec.mr.ExecReducer</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.auto.reducer.parallelism</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.authorization.manager</name><value>org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.client.connect.timeout</name><value>1000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapred.mode</name><value>nonstrict</value><source>programatically</source><source>job.xml</source></property>
<property><name>numFiles</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.azure.user.agent.prefix</name><value>User-Agent: APN/1.0 Hortonworks/1.0 HDP/2.6.5.0-292</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.reject-unresolved-dn-topology-mapping</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.swebhdfs.impl</name><value>org.apache.hadoop.fs.SWebHdfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.ssl.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.connection.establish.timeout</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.expire.trackers.interval</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.join.factor</name><value>1.1</value><source>programatically</source><source>job.xml</source></property>
<property><name>location</name><value>hdfs://ip-10-11-21-11.alationdata.com:8020/apps/hive/warehouse/otherthings</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hwi.listen.port</name><value>9999</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.recovery.enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.retries.wait</name><value>3000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.zookeeper.quorum</name><value>ip-10-11-21-11.alationdata.com:2181</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.post.hooks</name><value>org.apache.hadoop.hive.ql.hooks.ATSHook</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cluster.delegation.token.store.zookeeper.connectString</name><value>ip-10-11-21-11.alationdata.com:2181</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.cache.level2.type</name><value>none</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.reduce.slowstart.completedmaps</name><value>0.05</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.output.fileoutputformat.compress.type</name><value>BLOCK</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.parallelcopies</name><value>30</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.container.size</name><value>682</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.delete.thread-count</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.pre.event.listeners</name><value>org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.client.max-retries</name><value>30</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.ssl.enabled.protocols</name><value>TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.http.address</name><value>0.0.0.0:50030</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.resource.memory-mb</name><value>5120</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.kerberos.kinit.command</name><value>kinit</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.output.fileoutputformat.compress.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.kerberos.internal.spnego.principal</name><value>${dfs.web.authentication.kerberos.principal}</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.fpp</name><value>0.01</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.convert.join.bucket.mapjoin.tez</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.container.log.backups</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.rpc-timeout.ms</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.running.map.limit</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.io.rcfile.record.interval</name><value>2147483647</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.ssl.hostname.verifier</name><value>DEFAULT</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.map.groupby.sorted</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.socket.read-timeout</name><value>60s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.archives.timestamps</name><value>1544814789372</value><source>programatically</source><source>job.xml</source></property>
<property><name>stream.stderr.reporter.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.connection.ssl.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.scheduler.client.thread-count</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compute.splits.in.am</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.seqfile.local.dir</name><value>/tmp/hadoop-hive/io/local</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.directoryscan.threads</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.counters.pull.interval</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.client.best-effort</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.cleaner.resource-sleep-ms</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.client.failover-retries</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.lineinputformat.linespermap</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.posix.attr.uid.name</name><value>uidNumber</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.queue.default.acl-administer-jobs</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.new.job.grouping.set.cardinality</name><value>30</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container-monitor.interval-ms</name><value>3000</value><source>programatically</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source></property>
<property><name>mapreduce.job.queuename</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.dns.nameserver</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>javax.jdo.option.NonTransactionalRead</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.webapp.rest-csrf.custom-header</name><value>X-XSRF-Header</value><source>programatically</source><source>job.xml</source></property>
<property><name>rawDataSize</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.skip.proc.count.autoincr</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cli.errors.ignore</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore</name><value>GET,OPTIONS,HEAD</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.mode.local.auto.inputbytes.max</name><value>134217728</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stageid.rearrange</name><value>none</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.automatic.close</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.framework.name</name><value>yarn</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.failover.sleep.max.millis</name><value>15000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.max-completed-applications</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.staging-dir</name><value>/user</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.execution.mapjoin.minmax.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.path</name><value>cliservice</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nm.liveness-monitor.expiry-interval-ms</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.fetch.retry.enabled</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.disk.check.timeout</name><value>10m</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.archives</name><value>hdfs://ip-10-11-21-11.alationdata.com:8020/hdp/apps/2.6.5.0-292/mapreduce/mapreduce.tar.gz#mr-framework</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.autoCreateSchema</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.multiobjectdelete.enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.report.address</name><value>127.0.0.1:0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.memory.pool</name><value>0.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.metadataonly</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.balancer.max-no-move-interval</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapred.reduce.tasks.speculative.execution</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.task.factory</name><value>org.apache.hive.hcatalog.api.repl.exim.EximReplicationTaskFactory</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.lockmgr.zookeeper.default.partition.name</name><value>__HIVE_DEFAULT_ZOOKEEPER_PARTITION__</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.files.filesizes</name><value>4092,263760</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.conf.validation</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.query.id</name><value>hive_20181214193152_d7b98ad9-ba69-46bf-a81e-e601979c31a6</value><source>programatically</source><source>job.xml</source></property>
<property><name>ftp.client-write-packet-size</name><value>65536</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.kerberos.principal</name><value>hive/_HOST@EXAMPLE.COM</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.prewarm.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.io.sort.mb</name><value>358</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.kms.client.encrypted.key.cache.expiry</name><value>43200000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.fetch.task.conversion</name><value>more</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.taskmemorymanager.monitoringinterval</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.server.min.threads</name><value>200</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.dumpdir.clean.freq</name><value>0s</value><source>programatically</source><source>job.xml</source></property>
<property><name>ftp.blocksize</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.jaas.context</name><value>Client</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container.stderr.pattern</name><value>{*stderr*,*STDERR*}</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log-dirs</name><value>/hadoop/yarn/log</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.metastore.authorization.manager</name><value>org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.server.tcp.keepalive</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.groupby.checkinterval</name><value>4096</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.disk.check.min.gap</name><value>15m</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.df.interval</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.skip.checksum.errors</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.jetty.logs.serve.aliases</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.dynamic.partition.mode</name><value>nonstrict</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.remote-app-log-dir-suffix</name><value>logs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.bucketingsorting</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.mapredfiles</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.context</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.parallel</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.log.explain.output</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.edits.noeditlogchannelflush</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.serializations</name><value>org.apache.hadoop.io.serializer.WritableSerialization</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.rest-csrf.custom-header</name><value>X-XSRF-HEADER</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.skip.maxgroups</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.webapp.rest-csrf.custom-header</name><value>X-XSRF-Header</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.ha.fencing.ssh.connect-timeout</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.cpu.vcores</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.client.thread-count</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.random.device.file.path</name><value>/dev/urandom</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.max.total.tasks</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.costmodel.extended</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.binary.record.max.length</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.schema.validateTables</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.multi.insert.move.tasks.share.dependencies</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.fast.upload.buffer</name><value>disk</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.index.filter.compact.minsize</name><value>5368709120</value><source>programatically</source><source>job.xml</source></property>
<property><name>net.topology.script.file.name</name><value>/etc/hadoop/conf/topology_script.py</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.posix.attr.gid.name</name><value>gidNumber</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.windows-container.memory-limit.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.speculative-cap-total-tasks</name><value>0.01</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.abortedtxn.threshold</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.bp-ready.timeout</name><value>20</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client-write-packet-size</name><value>65536</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.journalnode.https-address</name><value>0.0.0.0:8481</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.enable.retrycache</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.convert.sortmerge.join.bigtable.selection.policy</name><value>org.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.audit.log.async</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.leveldb-state-store.path</name><value>/hadoop/yarn/timeline</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.udtf.auto.progress</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.journalnode.rpc-address</name><value>0.0.0.0:8485</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.fileio.profiling.sampling.percentage</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.encoding.strategy</name><value>SPEED</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.fetch.column.stats</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.zk-num-retries</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.app-checker.class</name><value>org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.reducers.bytes.per.reducer</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>numRows</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.reorder.nway.joins</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.container.log.limit.kb</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.group</name><value>hadoop</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.map.tasks.maximum</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.io.rcfile.tolerate.corruptions</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.max.typename.length</name><value>2000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.crypto.cipher.suite</name><value>AES/CTR/NoPadding</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.msck.path.validation</name><value>throw</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.test.rollbacktxn</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.fs.state-store.retry-policy-spec</name><value>2000, 500</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.hard-kill-timeout-ms</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.encrypt.data.transfer.cipher.key.bitlength</name><value>128</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.ipc.rpc.class</name><value>org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compat</name><value>0.12</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.support.append</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>file.replication</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.drop.cache.behind.writes</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.failover.max.attempts</name><value>15</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.index.compact.query.max.entries</name><value>10000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>rpc.metrics.quantile.enable</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.partitioner.class</name><value>org.apache.hadoop.hive.ql.io.DefaultHivePartitioner</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.jobname.length</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.bucket.cache.size</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.support.allow.format</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.file.impl</name><value>org.apache.hadoop.fs.local.LocalFs</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.file.buffer.size</name><value>131072</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.native.lib.available</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.history.reaper.interval</name><value>2m</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.balancer.block-move.timeout</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.limit.pushdown.memory.usage</name><value>0.04</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.lease-recheck-interval-ms</name><value>2000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.mmap.cache.size</name><value>256</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.xframe.value</name><value>SAMEORIGIN</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.delegation.key.update-interval</name><value>86400000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.execution.mapjoin.native.multikey.only.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.user.group.static.mapping.overrides</name><value>dr.who=;</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.metrics.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.ha.automatic-failover.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.script.operator.truncate.env</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.client-server.thread-count</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.fail-fast</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hashtable.key.count.adjustment</name><value>1.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.rcfile.use.explicit.header</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.global.init.file.location</name><value>/usr/hdp/current/hive-server2/conf/conf.server</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.read-lock-reporting-threshold-ms</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.end-notification.retry.attempts</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.stagingdir</name><value>.hive-staging</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.rest-csrf.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.schema.verification.record.version</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.https.need-auth</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.taskscheduler</name><value>org.apache.hadoop.mapred.JobQueueTaskScheduler</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.system-metrics-publisher.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size</name><value>10485760</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.async.exec.threads</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.skewjoin.compiletime</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.https.keystore.resource</name><value>ssl-client.xml</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.txns</name><value>1000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.webhdfs.impl</name><value>org.apache.hadoop.fs.WebHdfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.http-authentication.type</name><value>simple</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.server.max.threads</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.loadedjobs.cache.size</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.resource.percentage-physical-cpu-limit</name><value>80</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.recovery.dir</name><value>/var/log/hadoop-yarn/nodemanager/recovery-state</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.name.dir</name><value>/hadoop/hdfs/namenode</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.sparkfiles</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.try.direct.sql.ddl</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.service.metrics.file.location</name><value>/tmp/report.json</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.idle.session.check.operation</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.fileinputformat.split.minsize.per.rack</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.cluster.acls.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.client.progressmonitor.pollinterval</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>file.client-write-packet-size</name><value>65536</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log-aggregation.debug-enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.attr.group.name</name><value>cn</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.invalidate.work.pct.per.iteration</name><value>0.32f</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.dns.interface</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.resource.cpu-vcores</name><value>8</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.infer.bucket.sort.num.buckets.power.two</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>javax.jdo.option.DetachAllOnCommit</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.secondary.https-address</name><value>0.0.0.0:50091</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.point.lookup</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.compress.output</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.client.retry-interval-ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.cmrootdir</name><value>/user/hive/cmroot/</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.port</name><value>13562</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.path.style.access</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.container.liveness-monitor.interval-ms</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.fslock.fair</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exim.uri.scheme.whitelist</name><value>hdfs,pfile,file</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.lock.manager</name><value>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.display.partition.cols.separately</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.conf.hidden.list</name><value>javax.jdo.option.ConnectionPassword,hive.server2.keystore.password</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.scheduler.maximum-allocation-mb</name><value>5120</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.lock.mapred.only.operation</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.base.delta.ratio</name><value>8</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.task.scale.memory.reserve-fraction.min</name><value>0.3</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.minimum-allowed-tasks</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hbase.generatehfiles</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.input.format</name><value>org.apache.hadoop.hive.ql.io.HiveInputFormat</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.taskcontroller</name><value>org.apache.hadoop.mapred.DefaultTaskController</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.datestring.cache.size</name><value>200000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.admin.client.thread-count</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.leveldb-timeline-store.path</name><value>/hadoop/yarn/timeline</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.reducer.preempt.delay.sec</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3native.client-write-packet-size</name><value>65536</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.client.thread-count</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.userlog.limit.kb</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.minicluster.fixed.ports</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.userlog.retain.hours</name><value>24</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.providers.combined</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.notification.sequence.lock.retry.sleep.interval</name><value>500</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.conf.restricted.list</name><value>hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.committer.task.cleanup.needed</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.block-placement-policy.default.prefer-local-node</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.check.memory.rows</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.monitor.capacity.preemption.total_preemption_per_round</name><value>0.1</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.fs-limits.max-blocks-per-file</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.client.application-client-protocol.poll-interval-ms</name><value>200</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.default.stripe.size</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>columns</name><value>id,stuff_id</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.decode.partition.name</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.secure</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.exec.inplace.progress</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.sensitive-config-keys</name><value>
    secret$
    password$
    ssl.keystore.pass$
    fs.s3.*[Ss]ecret.?[Kk]ey
    fs.s3a.*.server-side-encryption.key
    fs.azure.account.key.*
    credential$
    oauth.*token$
    hadoop.security.sensitive-config-keys
  </value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.store.in-memory.staleness-period-mins</name><value>10080</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.output.format.class</name><value>org.apache.hadoop.hive.ql.io.HiveOutputFormatImpl</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.parquet.timestamp.skip.conversion</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.outerjoin.supports.filters</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.groupby.orderby.position.alias</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.scheduler.class</name><value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.logging.operation.level</name><value>EXECUTION</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.auth_to_local</name><value>DEFAULT</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.heartbeat.interval</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.bind.host</name><value>ip-10-11-21-11.alationdata.com</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile.params</name><value>-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.address</name><value>0.0.0.0:45454</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.fs-limits.max-xattr-size</name><value>16384</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.java.opts</name><value>-Xmx410m</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.recovery.store.leveldb.path</name><value>/hadoop/mapreduce/jhs</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.connection-keep-alive.enable</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.deserialization.factor</name><value>1.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.cache.cleanup.interval-ms</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.thrift.framed.transport.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.write.stale.datanode.ratio</name><value>1.0f</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.authentication.ldap.groupClassKey</name><value>groupOfNames</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.script.maxerrsize</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.key.prefix.reserve.length</name><value>24</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.history.retention.attempted</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.failover-controller.cli-check.rpc-timeout.ms</name><value>20000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.cleaner.period-mins</name><value>1440</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.index.compact.file.ignore.hdfs</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.threads.keepalivetime</name><value>60</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.local.clientfactory.class.name</name><value>org.apache.hadoop.mapred.LocalClientFactory</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.sort.dynamic.partition</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.taskcache.levels</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.cluster.administrators</name><value> hadoop</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.pre.hooks</name><value>org.apache.hadoop.hive.ql.hooks.ATSHook</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.metastore.authorization.auth.reads</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.sasl.qop</name><value>auth</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.retry.policy.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.zookeeper.session.timeout</name><value>1200000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>nfs.file.dump.dir</name><value>/tmp/.hdfs-nfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.max.message.size</name><value>104857600</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.nodemanager-connect-retries</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.staging.root.dir</name><value>/tmp/hadoop-hive/mapred/staging</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.stats.ndv.densityfunction</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.container.max.java.heap.fraction</name><value>0.8</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.jobname.limit</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.size</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.fileinputformat.inputdir</name><value>hdfs://ip-10-11-21-11.alationdata.com:8020/tmp/hive/hdfs/f9f9016f-5d22-4202-bfec-0ab6e2519f06/_tmp_space.db/Values__Tmp__Table__2</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.healthchecker.interval</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.ugi.expire.after.access</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.list.cache.directives.num.responses</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.submithostaddress</name><value>10.11.21.11</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.blockreport.initialDelay</name><value>120</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.retry-after-no-speculate</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.in.test</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.rowoffset</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.index.filter.compact.maxsize</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.intermediate-done-dir</name><value>/mr-history/tmp</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.cpu.vcores</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.azure.sas.expiry.period</name><value>90d</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.plugin.pluginRegistryBundleCheck</name><value>LOG</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.leveldb-timeline-store.read-cache-size</name><value>104857600</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.blockreport.split.threshold</name><value>1000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.block.size</name><value>32M</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.journalnode.edits.dir</name><value>/hadoop/hdfs/journalnode</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.restart.recover</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.output.key.class</name><value>org.apache.hadoop.hive.ql.io.HiveKey</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.zk.connection.timeout.ms</name><value>15000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.webapp.address</name><value>0.0.0.0:8788</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.enforce.bucketmapjoin</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.generic-application-history.save-non-am-container-meta-info</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.max.start.attempts</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.resource.checked.volumes.minimum</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>ftp.replication</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.delegation-token.max-conf-size-bytes</name><value>12800</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.compression.codec.bzip2.library</name><value>system-native</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.encrypt.data.transfer</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.costmodel.local.fs.read</name><value>4.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.retry-delay.max.ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.service.metrics.hadoop2.component</name><value>hiveserver2</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.client.rpc.threads</name><value>8</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.shuffle.log.limit.kb</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.id</name><value>hive_hive_20181214193152_d7b98ad9-ba69-46bf-a81e-e601979c31a6</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.cm.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.query.string</name><value>INSERT INTO otherthings (id, stuff_id) VALUES (2, 1)</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.cache-store-class</name><value>org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.generic-application-history.store-class</name><value>org.apache.hadoop.yarn.server.applicationhistoryservice.NullApplicationHistoryStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.schema.validateColumns</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.max.worker.threads</name><value>500</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.concatenate.check.index</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.groupby.maxentries</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.timeout</name><value>300000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.constant.propagation</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.disallow.incompatible.col.type.changes</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3n.multipart.uploads.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.recovery.store.class</name><value>org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.groups.cache.warn.after.ms</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.fetch.thread-count</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.input.buffer.percent</name><value>0.7</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.data.dir</name><value>/hadoop/hdfs/data</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.accesstime.precision</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.decommission.max.concurrent.tracked.nodes</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.avoid.write.stale.datanode</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container-executor.class</name><value>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.use.SSL</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.heartbeats.in.second</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.script.allow.partial.consumption</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.windows-container.cpu-limit.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.write.exclude.nodes.cache.expiry.interval.millis</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.max.partitions</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.fs.state-store.num-retries</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.costmodel.hdfs.read</name><value>1.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>bucket_count</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.connectionPoolingType</name><value>BONECP</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server.tcp.keepalive</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.files</name><value>hdfs://ip-10-11-21-11.alationdata.com:8020/tmp/hive/hdfs/f9f9016f-5d22-4202-bfec-0ab6e2519f06/hive_2018-12-14_19-31-52_529_6544269616838035925-5/-mr-10004/08fcd084-0fb8-4767-b780-719d3deb0d4c/map.xml#map.xml,hdfs://ip-10-11-21-11.alationdata.com:8020/user/hdfs/.staging/job_1544814832146_0004/libjars/hive-hcatalog-core.jar</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.use.datanode.hostname</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.authorization.sqlstd.confwhitelist</name><value>hive\.auto\..*|hive\.cbo\..*|hive\.convert\..*|hive\.exec\.dynamic\.partition.*|hive\.exec\.max\.dynamic\.partitions.*|hive\.exec\.compress\..*|hive\.exec\.infer\..*|hive\.exec\.mode.local\..*|hive\.exec\.orc\..*|hive\.exec\.parallel.*|hive\.explain\..*|hive\.fetch.task\..*|hive\.groupby\..*|hive\.hbase\..*|hive\.index\..*|hive\.index\..*|hive\.intermediate\..*|hive\.join\..*|hive\.limit\..*|hive\.log\..*|hive\.mapjoin\..*|hive\.merge\..*|hive\.optimize\..*|hive\.orc\..*|hive\.outerjoin\..*|hive\.parquet\..*|hive\.ppd\..*|hive\.prewarm\..*|hive\.server2\.proxy\.user|hive\.skewjoin\..*|hive\.smbjoin\..*|hive\.stats\..*|hive\.tez\..*|hive\.vectorized\..*|fs\.defaultFS|ssl\.client\.truststore\.location|distcp\.atomic|distcp\.ignore\.failures|distcp\.preserve\.status|distcp\.preserve\.rawxattrs|distcp\.sync\.folders|distcp\.delete\.missing\.source|distcp\.keystore\.resource|distcp\.liststatus\.threads|distcp\.max\.maps|distcp\.copy\.strategy|distcp\.skip\.crc|distcp\.copy\.overwrite|distcp\.copy\.append|distcp\.map\.bandwidth\.mb|distcp\.dynamic\..*|distcp\.meta\.folder|distcp\.copy\.listing\.class|distcp\.filters\.class|distcp\.options\.skipcrccheck|distcp\.options\.m|distcp\.options\.numListstatusThreads|distcp\.options\.mapredSslConf|distcp\.options\.bandwidth|distcp\.options\.overwrite|distcp\.options\.strategy|distcp\.options\.i|distcp\.options\.p.*|distcp\.options\.update|distcp\.options\.delete|mapred\.map\..*|mapred\.reduce\..*|mapred\.output\.compression\.codec|mapred\.job\.queue\.name|mapred\.output\.compression\.type|mapred\.min\.split\.size|mapreduce\.job\.reduce\.slowstart\.completedmaps|mapreduce\.job\.queuename|mapreduce\.job\.tags|mapreduce\.job\.hdfs-servers|mapreduce\.job\.send-token-conf|mapreduce\.input\.fileinputformat\.split\.minsize|mapreduce\.map\..*|mapreduce\.reduce\..*|mapreduce\.output\.fileoutputformat\.compress\.codec|mapreduce\.output\.fileoutputformat\.compress\.type|oozie\..*|tez\.am\..*|tez\.task\..*|tez\.runtime\..*|tez\.queue\.name|hive\.exec\.reducers\.bytes\.per\.reducer|hive\.client\.stats\.counters|hive\.exec\.default\.partition\.name|hive\.exec\.drop\.ignorenonexistent|hive\.counters\.group\.name|hive\.default\.fileformat\.managed|hive\.enforce\.bucketing|hive\.enforce\.bucketmapjoin|hive\.enforce\.sorting|hive\.enforce\.sortmergebucketmapjoin|hive\.cache\.expr\.evaluation|hive\.hashtable\.loadfactor|hive\.hashtable\.initialCapacity|hive\.ignore\.mapjoin\.hint|hive\.limit\.row\.max\.size|hive\.mapred\.mode|hive\.map\.aggr|hive\.compute\.query\.using\.stats|hive\.exec\.rowoffset|hive\.variable\.substitute|hive\.variable\.substitute\.depth|hive\.autogen\.columnalias\.prefix\.includefuncname|hive\.autogen\.columnalias\.prefix\.label|hive\.exec\.check\.crossproducts|hive\.compat|hive\.exec\.concatenate\.check\.index|hive\.display\.partition\.cols\.separately|hive\.error\.on\.empty\.partition|hive\.execution\.engine|hive\.exec\.copyfile\.maxsize|hive\.exim\.uri\.scheme\.whitelist|hive\.file\.max\.footer|hive\.insert\.into\.multilevel\.dirs|hive\.localize\.resource\.num\.wait\.attempts|hive\.multi\.insert\.move\.tasks\.share\.dependencies|hive\.support\.quoted\.identifiers|hive\.resultset\.use\.unique\.column\.names|hive\.analyze\.stmt\.collect\.partlevel\.stats|hive\.server2\.logging\.operation\.level|hive\.support\.sql11\.reserved\.keywords|hive\.exec\.job\.debug\.capture\.stacktraces|hive\.exec\.job\.debug\.timeout|hive\.exec\.max\.created\.files|hive\.exec\.reducers\.max|hive\.reorder\.nway\.joins|hive\.output\.file\.extension|hive\.exec\.show\.job\.failure\.debug\.info|hive\.exec\.tasklog\.debug\.timeout</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.tez.sessions.per.default.queue</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>file.blocksize</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.kill.max</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.schema.verification</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.nodemanager.minimum.version</name><value>NONE</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.kill-escape.launch-command-line</name><value>slider-agent,LLAP</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.list.cache.pools.num.responses</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.batch.retrieve.max</name><value>300</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.service.metrics.class</name><value>org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.cache.revocation.polling.ms</name><value>500</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.querylog.location</name><value>/tmp/hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.load.dynamic.partitions.thread</name><value>15</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.read.shortcircuit.streams.cache.size</name><value>4096</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.mapfile.bloom.size</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.support.quoted.identifiers</name><value>column</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.dictionary.key.size.threshold</name><value>0.8</value><source>programatically</source><source>job.xml</source></property>
<property><name>net.topology.impl</name><value>org.apache.hadoop.net.NetworkTopology</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.kerberos.principal.pattern</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.node-labels.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>name</name><value>default.otherthings</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.trash.checkpoint.interval</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3.replication</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.cookie.max.age</name><value>86400s</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.client.max-retries</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.maps</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.zookeeper.namespace</name><value>hiveserver2</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.resources-handler.class</name><value>org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.maxattempts</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.cookie.is.secure</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.dir</name><value>/user/hdfs/.staging/job_1544814832146_0004</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.acl-view-job</name><value> </value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.user.agent.prefix</name><value>User-Agent: APN/1.0 Hortonworks/1.0 HDP/2.6.5.0-292</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.dir</name><value>/hadoop/hdfs/namesecondary</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.lazysimple.extended_boolean_literal</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.type</name><value>simple</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.schema.evolution</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.java.secure.random.algorithm</name><value>SHA1PRNG</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.autogather</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.initial.metadata.count.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.resource.du.reserved</name><value>104857600</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.classpath.files</name><value>/user/hdfs/.staging/job_1544814832146_0004/libjars/hive-hcatalog-core.jar</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.server.log.slow.rpc</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.disk-health-checker.min-healthy-disks</name><value>0.25</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.address</name><value>0.0.0.0:8040</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.viewfs.impl</name><value>org.apache.hadoop.fs.viewfs.ViewFs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.approx.max.load.tasks</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.warehouse.dir</name><value>/apps/hive/warehouse</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.map.output.collector.class</name><value>org.apache.hadoop.mapred.MapTask$MapOutputBuffer</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.skip.corrupt.data</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.ttl-ms</name><value>2678400000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.blocksize</name><value>134217728</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.request.header.size</name><value>6144</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.admin.thread-count</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>tfile.io.chunk.size</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.entity.separator</name><value>@</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.mapper.class</name><value>org.apache.hadoop.hive.ql.exec.mr.ExecMapper</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.combine.progress.records</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.local.scratchdir</name><value>/tmp/hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.cleaner.initial-delay-mins</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.ftp.host.port</name><value>21</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.committer.setup.cleanup.needed</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.hostname</name><value>0.0.0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.limit.row.max.size</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>javax.jdo.option.Multithreaded</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.session.check.interval</name><value>6h</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.hybridgrace.minnumpartitions</name><value>16</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.timedout.txn.reaper.start</name><value>100s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.downloaded.resources.dir</name><value>/tmp/f9f9016f-5d22-4202-bfec-0ab6e2519f06_resources</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.leveldb-state-store.path</name><value>/tmp/hadoop-hive/yarn/system/rmstore</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.keytab</name><value>/etc/security/keytab/jhs.service.keytab</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.kill-escape.user</name><value>hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.zookeeper.connection.basesleeptime</name><value>1000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.health-monitor.connect-retry-interval.ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>manage.include.files</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.webapp.rest-csrf.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.infer.bucket.sort</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.max.objects</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.max.full.block.report.leases</name><value>6</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.ignore.mapjoin.hint</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.amlauncher.thread-count</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.archive.intermediate.archived</name><value>_INTERMEDIATE_ARCHIVED</value><source>programatically</source><source>job.xml</source></property>
<property><name>nfs.wtmax</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.cm.interval</name><value>3600s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.zookeeper.client.port</name><value>2181</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.webapp.xfs-filter.xframe-options</name><value>SAMEORIGIN</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.block.write.retries</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.output.value.class</name><value>org.apache.hadoop.io.BytesWritable</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.acl.enable</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>file.outputformat</name><value>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.execution.mapjoin.overflow.repeated.threshold</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.orm.retrieveMapNullsAsEmptyStrings</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.adl.oauth2.access.token.provider.type</name><value>ClientCredential</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.hdfs.impl</name><value>org.apache.hadoop.fs.Hdfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.service.metrics.reporter</name><value>HADOOP2</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.max.variance</name><value>0.01</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.worker.threads</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.credential.provider.path</name><value>jceks://file/usr/hdp/current/hive-server2/conf/conf.server/hive-site.jceks</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.dump.include.acid.tables</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.analyze.stmt.collect.partlevel.stats</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.block.scanner.volume.bytes.per.second</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.fs-limits.max-component-length</name><value>255</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.map.aggr.hash.percentmemory</name><value>0.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.explain.user</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.complete.cancel.delegation.tokens</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.io.rcfile.record.buffer.size</name><value>4194304</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.recovery.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.nodemanagers.heartbeat-interval-ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.max.reader.wait</name><value>1000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.output.compress.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.enable.doAs</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hmshandler.retry.attempts</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.har.impl</name><value>org.apache.hadoop.fs.HarFs</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.process-kill-wait.ms</name><value>2000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.authentication.ldap.groupMembershipKey</name><value>member</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.zookeeper.parent-znode</name><value>/hadoop-ha</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.smbjoin.cache.rows</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hbase.wal.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.admin.acl</name><value>yarn</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3native.blocksize</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.logging.operation.log.location</name><value>/tmp/hive/operation_logs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.tez.default.queues</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.threads.max</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.state-store.max-completed-applications</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>columns.types</name><value>int:int</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.peer.stats.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.ftp.impl</name><value>org.apache.hadoop.fs.ftp.FtpFs</value><source>programatically</source><source>job.xml</source></property>
<property><name>_hive.local.session.path</name><value>/tmp/hive/f9f9016f-5d22-4202-bfec-0ab6e2519f06</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.idlethreshold</name><value>8000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.thrift.compact.protocol.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.initiator.failed.compacts.threshold</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>ftp.bytes-per-checksum</name><value>512</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.count.open.txns.interval</name><value>1s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.hybridgrace.memcheckfrequency</name><value>1024</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.start.cleanup.scratchdir</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.socket.send.buffer.size</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.authorization.createtable.owner.grants</name><value>INSERT,SELECT,UPDATE,DELETE</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.clean.until</name><value>0.8</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.support.dynamic.service.discovery</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.groupby.flush.percent</name><value>0.1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.display.per-user-apps</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.plan</name><value>hdfs://ip-10-11-21-11.alationdata.com:8020/tmp/hive/hdfs/f9f9016f-5d22-4202-bfec-0ab6e2519f06/hive_2018-12-14_19-31-52_529_6544269616838035925-5/-mr-10004/08fcd084-0fb8-4767-b780-719d3deb0d4c</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.drop.ignorenonexistent</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.connection.maxidletime</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.smallfiles.avgsize</name><value>16000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.connect.retries</name><value>24</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.orc.row.index.stride.dictionary.check</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.common.configuration.version</name><value>0.23.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.ifile.readahead.bytes</name><value>4194304</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.map.index.interval</name><value>128</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.cgroups.mount-path</name><value>/cgroup</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms</name><value>300000</value><source>programatically</source><source>job.xml</source></property>
<property><name>javax.jdo.option.ConnectionURL</name><value>jdbc:mysql://ip-10-11-21-11.alationdata.com/hive?createDatabaseIfNotExist=true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.show.job.failure.debug.info</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.execution.mapjoin.native.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>tfile.fs.output.buffer.size</name><value>262144</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.attr.member</name><value>member</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.health-checker.script.timeout-ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.tez.initialize.default.sessions</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.handler.count</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.authenticator.manager</name><value>org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.join.emit.interval</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.max.partition.factor</name><value>2.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.port</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.fs-limits.min-block-size</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.with-user-dir</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.handler.count</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.filter.in.factor</name><value>1.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.followby.gby.localtask.max.memory.usage</name><value>0.55</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.sample.seednumber</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.default.fileformat.managed</name><value>TextFile</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.connect.retry-interval.ms</name><value>15000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.ppd.storage</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.hostname</name><value>ip-10-11-21-11.alationdata.com</value><source>programatically</source><source>job.xml</source></property>
<property><name>nfs.dump.dir</name><value>/tmp/.hdfs-nfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.client.future.timeout</name><value>60s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.script.auto.progress</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.parallel.thread.number</name><value>8</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.retrycache.heap.percent</name><value>0.03f</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.xattrs.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.txn.store.impl</name><value>org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.webapp.address</name><value>ip-10-11-21-11.alationdata.com:19888</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.index.autoupdate</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.slowtaskthreshold</name><value>1.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.address</name><value>ip-10-11-21-11.alationdata.com:8050</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.map.aggr.hash.force.flush.memory.threshold</name><value>0.9</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.submitviachild</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.fixedDatastore</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.connection.timeout</name><value>200000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.in.tez.test</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.orc.compute.splits.num.threads</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.block.access.token.enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.sasl.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs</name><value>86400</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.sort.spill.percent</name><value>0.7</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.end-notification.max.attempts</name><value>5</value><source>mapred-default.xml</source></property>
<property><name>dfs.namenode.safemode.extension</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.script.serde</name><value>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.heartbeat.interval</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapred.local.mem</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.content-summary.limit</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.cardinality.check</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.store-class</name><value>org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>javax.jdo.option.ConnectionDriverName</name><value>com.mysql.jdbc.Driver</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile.reduces</name><value>0-2</value><source>programatically</source><source>job.xml</source></property>
<property><name>iocontext.input.name</name><value>mapreduce</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.edits.journal-plugin.qjournal</name><value>org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.client.fd-retain-secs</name><value>300</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.failure.hooks</name><value>org.apache.hadoop.hive.ql.hooks.ATSHook</value><source>programatically</source><source>job.xml</source></property>
<property><name>COLUMN_STATS_ACCURATE</name><value>{\"BASIC_STATS\":\"true\"}</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.dynamic.partition.pruning.max.data.size</name><value>104857600</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.nodes.exclude-path</name><value>/etc/hadoop/conf/yarn.exclude</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.group.hierarchy.levels</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.bind-host</name><value>0.0.0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.failover-controller.graceful-fence.connection.retries</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.jvm.numtasks</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.index.filter</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.rpc-address</name><value>ip-10-11-21-11.alationdata.com:8020</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.dispatcher.exit-on-error</name><value>true</value><source>programatically</source></property>
<property><name>hive.exec.orc.default.compress</name><value>ZLIB</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.localtask.max.memory.usage</name><value>0.9</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.rest-csrf.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.default.block.size</name><value>268435456</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.decommission.blocks.per.interval</name><value>500000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.image.compress</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3n.multipart.copy.block.size</name><value>5368709120</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.am.liveness-monitor.expiry-interval-ms</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.ubertask.maxreduces</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.safemode.min.datanodes</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.attempts.maximum</name><value>20</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore</name><value>GET,OPTIONS,HEAD</value><source>programatically</source><source>job.xml</source></property>
<property><name>parquet.memory.pool.ratio</name><value>0.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.move.interval-ms</name><value>180000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.outofband.heartbeat</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.uris</name><value> </value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.parallel.ops.in.session</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3.maxRetries</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.test.fail.compaction</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.multipart.size</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.initiator.on</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.smalltable.filesize</name><value>25000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.client.connect.retry.delay</name><value>5s</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage</name><value>90</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.ssl.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.backup.address</name><value>0.0.0.0:50100</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user</name><value>nobody</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.check.period</name><value>60</value><source>programatically</source><source>job.xml</source></property>
<property><name>nfs.allow.insecure.ports</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cache.expr.evaluation</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.ssl.protocol.blacklist</name><value>SSLv2,SSLv3</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.transfer.socket.send.buffer.size</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>net.topology.node.switch.mapping.impl</name><value>org.apache.hadoop.net.ScriptBasedMapping</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.max.created.files</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.swift.impl</name><value>org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.proxyuser.hcat.groups</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.scratchdir</name><value>/tmp/hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.node.name</name><value>Stage-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.shuffle.log.backups</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.dump.metadata.only</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.partitions.dump.parallelism</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.rdbms.useLegacyNativeValueStrategy</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.edit.log.autoroll.multiplier.threshold</name><value>2.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container-metrics.unregister-delay-ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.timedout.txn.reaper.interval</name><value>180s</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.user.provider.user.pattern</name><value>^[A-Za-z_][A-Za-z0-9._-]*[$]?$</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.defaultFS</name><value>hdfs://ip-10-11-21-11.alationdata.com:8020</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.socket.recv.buffer</name><value>8192</value><source>programatically</source><source>job.xml</source></property>
<property><name>tmpjars</name><value>file:///usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.merge.inmem.threshold</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.enforce.sorting</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds</name><value>3600</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction</name><value>0.75f</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.metastore.authenticator.manager</name><value>org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.map.index.skip</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name><value>${dfs.web.authentication.kerberos.principal}</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.rpc.query.plan</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.dumpdir.ttl</name><value>7d</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.resource.mb</name><value>512</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.serdes.using.metastore.for.schema</name><value>org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.session.history.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>serialization.format</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.ppd.recognizetransivity</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.tasklog.debug.timeout</name><value>20000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.disk-health-checker.interval-ms</name><value>120000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.memory.mb</name><value>1024</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.maxtaskfailures.per.tracker</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.crypto.buffer.size</name><value>8192</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.scheduler.minimum-allocation-vcores</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.keytab</name><value>/etc/krb5.keytab</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</name><value>hadoop-yarn</value><source>programatically</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.ipc.ProtocolMetaInfoPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source></property>
<property><name>hive.vectorized.adaptor.usage.mode</name><value>all</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.fs.state-store.retry-interval-ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.worker.keepalive.time</name><value>60s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.rcfile.use.sync.cache</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.aux-services</name><value>mapreduce_shuffle,spark_shuffle,spark2_shuffle</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.job.debug.timeout</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.table.type.mapping</name><value>CLASSIC</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.correlation</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.compression.codecs</name><value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.webapp.xfs-filter.xframe-options</name><value>SAMEORIGIN</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.split.metainfo.maxsize</name><value>10000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.mode.local.auto</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.skewjoin.mapjoin.min.split</name><value>33554432</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.log-aggregation.file-formats</name><value>IndexedFormat,TFile</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.logaggregation.threadpool-size-max</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.min.partition.factor</name><value>0.25</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.read.timeout</name><value>180000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.task.container.log.backups</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.gather.num.threads</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.input.format.class</name><value>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.default.block.padding</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.entity.capture.transform</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.connect.max.retries</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3.buffer.dir</name><value>/tmp/hadoop-hive/s3</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.store.class</name><value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.index.compact.query.max.size</name><value>10737418240</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.min.worker.threads</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.perf.logger</name><value>org.apache.hadoop.hive.ql.log.PerfLogger</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.convert.join.noconditionaltask</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.max.transfer.threads</name><value>1024</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.rawstore.impl</name><value>org.apache.hadoop.hive.metastore.ObjectStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.fileinputformat.input.dir.recursive</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.log.every.n.records</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>atlas.hook.hive.minThreads</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.dynamic.partition.pruning</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.bucketmapjoin</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.token.validity</name><value>36000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.instrumentation</name><value>org.apache.hadoop.mapred.JobTrackerMetricsInst</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.secondary.http-address</name><value>ip-10-11-21-11.alationdata.com:50090</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.fuse.timer.period</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.client.failover-proxy-provider</name><value>org.apache.hadoop.yarn.client.RequestHedgingRMFailoverProxyProvider</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.resourcemanager.minimum.version</name><value>NONE</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.skip.maxrecords</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.delta.num.threshold</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.top.num.users</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.application.classpath</name><value>/usr/hdp/2.6.5.0-292/hadoop/conf,/usr/hdp/2.6.5.0-292/hadoop/*,/usr/hdp/2.6.5.0-292/hadoop/lib/*,/usr/hdp/current/hadoop-hdfs-client/*,/usr/hdp/current/hadoop-hdfs-client/lib/*,/usr/hdp/current/hadoop-yarn-client/*,/usr/hdp/current/hadoop-yarn-client/lib/*,/usr/hdp/current/ext/hadoop/*</value><source>programatically</source><source>job.xml</source></property>
<property><name>atlas.hook.hive.maxThreads</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.configuration.provider-class</name><value>org.apache.hadoop.yarn.LocalConfigurationProvider</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.indexcache.mb</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.point.lookup.min</name><value>31</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.localize.resource.num.wait.attempts</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.autoStartMechanismMode</name><value>ignored</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.input.format.sorted</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.tmp.dir</name><value>/tmp/hadoop-hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.https.address</name><value>ip-10-11-21-11.alationdata.com:8090</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.enforce.sortmergebucketmapjoin</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.limit.optimize.limit.file</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.done-dir</name><value>/ats/done/</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.avoid.read.stale.datanode</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.cluster.local.dir</name><value>/tmp/hadoop-hive/mapred/local</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.move.thread-count</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.rdbms.initializeColumnInfo</name><value>NONE</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.store.in-memory.check-period-mins</name><value>720</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.jar</name><value>/user/hdfs/.staging/job_1544814832146_0004/job.jar</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.multipart.threshold</name><value>2147483647</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cli.prompt</name><value>hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.cache.pinobjtypes</name><value>Table,Database,Type,FieldSchema,Order</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hmshandler.force.reload.conf</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.legacy.schema.for.all.serdes</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.fs.handler.class</name><value>org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.period</name><value>21600</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.zk-address</name><value>ip-10-11-21-11.alationdata.com:2181</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.job.monitor.timeout</name><value>60s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.kms.client.encrypted.key.cache.low-watermark</name><value>0.3f</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.replication</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.datanode.registration.ip-hostname-check</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.reducer.unconditional-preempt.delay.sec</name><value>300</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.shared.file.descriptor.paths</name><value>/dev/shm,/tmp</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.recovery.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.execute.setugi</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.aux-services.spark_shuffle.classpath</name><value>/usr/hdp/2.6.5.0-292/spark/aux/*</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.instrumentation.requires.admin</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.startup.delay.block.deletion.sec</name><value>3600</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.resource-tracker.client.thread-count</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.reliable</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.failover-controller.new-active.rpc-timeout.ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.support.concurrency</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.server.max.connections</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>transient_lastDdlTime</name><value>1544815855</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.job.task.listener.thread-count</name><value>30</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.connectionPool.maxPoolSize</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.scheduler.maximum-allocation-vcores</name><value>8</value><source>programatically</source><source>job.xml</source></property>
<property><name>net.topology.script.number.args</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.socket.send.buffer</name><value>8192</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.healthchecker.script.timeout</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.runtime.linux.docker.allowed-container-networks</name><value>host,none,bridge</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.cpu.vcores</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>ftp.stream-buffer-size</name><value>4096</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.int.timestamp.conversion.in.seconds</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.client.nodemanager-connect.max-wait-ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.rpc.socket.factory.class.default</name><value>org.apache.hadoop.net.StandardSocketFactory</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.dns.log-slow-lookups.threshold.ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.zookeeper.acl</name><value>world:anyone:rwcda</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.idle.session.timeout</name><value>7d</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.groups.cache.background.reload</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.optimized.hashtable.wbsize</name><value>8388608</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.connect.retry.interval</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.speculative</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.transform.escape.input</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.bind-host</name><value>0.0.0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>serialization.ddl</name><value>struct otherthings { i32 id, i32 stuff_id}</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.merge.percent</name><value>0.66</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.name.dir.restore</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.nested-level</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>_hive.hdfs.session.path</name><value>/tmp/hive/hdfs/f9f9016f-5d22-4202-bfec-0ab6e2519f06</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.webapp.cross-origin.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.read.timeout.ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mv.files.thread</name><value>15</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hash.table.inflation.factor</name><value>2.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.ubertask.enable</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.signature.secret.file</name><value>/home/hive/hadoop-http-auth-signature-secret</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.client.fd-clean-interval-secs</name><value>60</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.top.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>columns.comments</name><value>\u0000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.default.buffer.size</name><value>262144</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.bytes-per-checksum</name><value>512</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.check.interval</name><value>300L</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.node-labels.fs-store.impl.class</name><value>org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.fs-limits.max-xattrs-per-inode</name><value>32</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.max.num.delta</name><value>500</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.node-labels.fs-store.root-dir</name><value>/system/yarn/node-labels</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.image.compression.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.direct.sql.batch.size</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.principal</name><value>jhs/_HOST@REALM.TLD</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.persist.jobstatus.active</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compute.query.using.stats</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.txn.strict.locking.mode</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.querylog.enable.plan.progress</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.mapfiles</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.adl.impl</name><value>org.apache.hadoop.fs.adl.AdlFileSystem</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.fetch.partition.stats</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.ha.zkfc.nn.http.timeout.ms</name><value>20000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.use.datanode.hostname</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.command.whitelist</name><value>set,reset,dfs,add,list,delete,reload,compile</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.fast.upload.active.blocks</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.webapp.https.address</name><value>ip-10-11-21-11.alationdata.com:8190</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.txn.manager.dump.lock.state.on.acquire.timeout</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>tfile.fs.input.buffer.size</name><value>262144</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.storage.policy.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.ssl.keystores.factory.class</name><value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.admin-env</name><value>MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.split.strategy</name><value>HYBRID</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.am.max-attempts</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.txn.timeout</name><value>300</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.emit-timeline-data</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.cleaner.enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.scratch.dir.permission</name><value>700</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.failover-controller.graceful-fence.rpc-timeout.ms</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.balance.bandwidthPerSec</name><value>6250000</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.mapfile.bloom.error.rate</name><value>0.005</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.response.header.size</name><value>6144</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.block.write.replace-datanode-on-failure.enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.mmap.cache.timeout.ms</name><value>3600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.rcfile.block.level</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.blocks.per.postponedblocks.rescan</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.kerberos.principal</name><value>HTTP/_HOST@LOCALHOST</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.client-server.address</name><value>0.0.0.0:8045</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.command-opts</name><value>-Xmx410m</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.collect.tablekeys</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.zookeeper.clean.extra.nodes</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hadoop.supports.splittable.combineinputformat</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.skip.proc.count.autoincr</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.event.message.factory</name><value>org.apache.hadoop.hive.metastore.messaging.json.JSONMessageFactory</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.max-retries</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>javax.jdo.option.ConnectionUserName</name><value>hive</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.path.based.cache.retry.interval.ms</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.query.result.fileformat</name><value>TextFile</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.maxtasks.perjob</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.monitor.capacity.preemption.natural_termination_factor</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.collect.scancols</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.proxyuser.hcat.hosts</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.system.acls</name><value>sasl:yarn@, sasl:mapred@, sasl:hdfs@</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3native.stream-buffer-size</name><value>4096</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile.reduce.params</name><value>-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.fileinputformat.split.minsize.per.node</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.permissions.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.shell.safely.delete.limit.num.files</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.allow.user.substitution</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.health-monitor.check-interval.ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.delta.pct.threshold</name><value>0.1f</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.cookie.auth.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.max.dynamic.partitions.pernode</name><value>2000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.recovery.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.audit.loggers</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.health-checker.interval-ms</name><value>135000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.acls.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.ndv.error</name><value>20.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.acl-modify-job</name><value> </value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.work-preserving-recovery.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.service.metrics.hadoop2.frequency</name><value>30s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.cm.retain</name><value>24h</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.kerberos.min.seconds.before.relogin</name><value>60</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.handler-thread-count</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.writeset.reaper.interval</name><value>60s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.skewjoin</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.cross-origin.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.size.per.task</name><value>256000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.webapp.xfs-filter.xframe-options</name><value>SAMEORIGIN</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.task.scale.memory.reserve.fraction</name><value>-1.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.scan-interval-seconds</name><value>15</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.localize.resource.wait.interval</name><value>5000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.proxyuser.hive.hosts</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.convert.join.use.nonstaged</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.distinct.rewrite</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.max.open.txns</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.aux-services.spark_shuffle.class</name><value>org.apache.spark.network.yarn.YarnShuffleService</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.encrypt.data.transfer.cipher.suites</name><value>AES/CTR/NoPadding</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.transfer.buffer.size</name><value>131072</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.plan.serialization.format</name><value>kryo</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log-container-debug-info.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.list.encryption.zones.num.responses</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.event.db.clean.maxevents</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.job.committer.cancel-timeout</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.hostname</name><value>0.0.0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.clear.dangling.scratchdir</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.rework.mapredwork</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.sampling.orderby</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.log-aggregation.retain-check-interval-seconds</name><value>-1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.orcfile.stripe.level</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.compression.strategy</name><value>SPEED</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.har.impl.disable.cache</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.max.variable.length</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.http-authentication.simple.anonymous.allowed</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.filter.group</name><value>(objectClass=group)</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.log-aggregation.file-controller.TFile.class</name><value>org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.persist.jobstatus.dir</name><value>/jobtracker/jobsInfo</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.script.trust</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.leveldb-state-store.compaction-interval-secs</name><value>3600</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.resource.cpu-vcores</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cluster.delegation.token.store.class</name><value>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.vectorized.execution.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.delayed.delegation-token.removal-interval-ms</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.scratchdir.lock</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.vmem-pmem-ratio</name><value>2.1</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.webapp.xfs-filter.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.key.prefix.max.length</name><value>150</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.cache.target-size-mb</name><value>10240</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.log.server.web-service.url</name><value>http://ip-10-11-21-11.alationdata.com:8188/ws/v1/applicationhistory</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.reducededuplication</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.orc.zerocopy</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.scheduler.monitor.enable</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.default.rcfile.serde</name><value>org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.azure.saskey.usecontainersaskeyforallaccess</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.convert.join</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.domain.socket.data.traffic</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.costmodel.network</name><value>150.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>adl.feature.ownerandgroup.enableupn</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.name</name><value>INSERT INTO otherthings (id, stuff_id) ...1)(Stage-1)</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.http.threads</name><value>40</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exim.strict.repl.tables</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.zk-state-store.parent-path</name><value>/rmstore</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.block-pinning.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.failure.retries</name><value>24</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.speculative</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.mover.max-no-move-interval</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.ttl</name><value>600s</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.fetch.retry.interval-ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.azure.local.sas.key.mode</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.replica.functions.root.dir</name><value>/user/hive/repl/functions/</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hwi.listen.host</name><value>0.0.0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.cachereport.intervalMsec</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.kerberos.keytab.file</name><value>/etc/security/keytabs/hive.service.keytab</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.maximum.data.length</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.failover-controller.active-standby-elector.zk.op.retries</name><value>120</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.batch.retrieve.table.partition.max</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>totalSize</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.log-aggregation.retain-seconds</name><value>2592000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.cookie.is.httponly</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.client.socket.timeout</name><value>1800s</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.webapp.address</name><value>0.0.0.0:8042</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.store.class</name><value>org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.replication.interval</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.client.fd-flush-interval-secs</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.local-dirs</name><value>/hadoop/yarn/local</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.bind-host</name><value>0.0.0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>nfs.mountd.port</name><value>4242</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.resultset.use.unique.column.names</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.adjacency.Stage-7</name><value>Stage-4,Stage-3,Stage-5</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.adjacency.Stage-6</name><value>Stage-0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.adjacency.Stage-5</name><value>Stage-6</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.zk.retry.interval.ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.adjacency.Stage-4</name><value>Stage-0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.uid.cache.secs</name><value>14400</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.costmodel.cpu</name><value>0.000001</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.aux-services.spark2_shuffle.classpath</name><value>/usr/hdp/2.6.5.0-292/spark2/aux/*</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.adjacency.Stage-3</name><value>Stage-0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.adjacency.Stage-1</name><value>Stage-7</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.adjacency.Stage-0</name><value>Stage-2</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.rest-csrf.browser-useragents-regex</name><value>^Mozilla.*,^Opera.*</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.reducer.new-api</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.variable.substitute.depth</name><value>40</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.resource.check.interval</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.fsdatasetcache.max.threads.per.volume</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>javax.jdo.PersistenceManagerFactoryClass</name><value>org.datanucleus.api.jdo.JDOPersistenceManagerFactory</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.output.value.class</name><value>org.apache.hadoop.io.Text</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.fetch.output.serde</name><value>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.conversion.rule</name><value>none</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hashtable.loadfactor</name><value>0.75</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.partition.columns.separate</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.convert.join.noconditionaltask.size</name><value>52428800</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.outliers.report.interval</name><value>1800000</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3n.multipart.uploads.block.size</name><value>67108864</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.exponential.backoff.slot.length</name><value>100ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.check.crossproducts</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.support.sql11.reserved.keywords</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.compress.intermediate</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.listbucketing</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.connection.timeout.ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.connect.timeout</name><value>180000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.am.max-attempts</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.http.address</name><value>0.0.0.0:50075</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.map.num.entries</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.authorization</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.amlauncher.log.command</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.merge.progress.records</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.sampling.orderby.percent</name><value>0.1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.event.clean.freq</name><value>0s</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.image.transfer.timeout</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.ifile.readahead</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.fshandler.threads</name><value>15</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.skip.start.attempts</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.uploader.server.thread-count</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.io.rcfile.column.number.conf</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.limit.optimize.fetch.max</name><value>50000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.ha.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.copyfile.maxsize</name><value>33554432</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.fileinputformat.split.minsize</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.txn.max.open.batch</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.ha.tail-edits.rolledits.timeout</name><value>60</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.ttl-enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.bin.path</name><value>/usr/hdp/2.6.5.0-292/hadoop/bin/hadoop</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.top.windows.minutes</name><value>1,5,25</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.backup.http-address</name><value>0.0.0.0:50105</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container.stderr.tail.bytes</name><value>4096</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.convert.sortmerge.join</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.delegation.token.max-lifetime</name><value>604800000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.maxattempts</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.cache.level2</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.groupby.skewindata</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.cleaner.run.interval</name><value>5000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>file.inputformat</name><value>org.apache.hadoop.mapred.TextInputFormat</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.image.transfer.bandwidthPerSec</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.copyfile.maxnumfiles</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.max.extra.edits.segments.retained</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.nm.uploader.replication.factor</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.fileformat.check</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.mmap.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.ubertask.maxmaps</name><value>9</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.output.committer.class</name><value>org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.in.place.progress</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.client.resolve.remote.symlinks</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.stream-buffer-size</name><value>4096</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.block.write.replace-datanode-on-failure.policy</name><value>DEFAULT</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.smb.number.waves</name><value>0.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.shuffle.log.separate</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.transport.mode</name><value>binary</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.seqfile.lazydecompress</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.ssl</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.aux.jars.path</name><value>file:///usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.schema.validateConstraints</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hwi.war.file</name><value>${env:HWI_WAR_FILE}</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.files.preserve.failedtasks</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.paging.maximum</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3native.bytes-per-checksum</name><value>512</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.reduce.shuffle.consumer.plugin.class</name><value>org.apache.hadoop.mapreduce.task.reduce.Shuffle</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.client.secret.bits</name><value>256</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.journalnode.http-address</name><value>0.0.0.0:8480</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hbase.snapshot.restoredir</name><value>/tmp</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.port</name><value>10001</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.keytab</name><value>/etc/krb5.keytab</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.user.home.dir.prefix</name><value>/user</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.staticuser.user</name><value>dr.who</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.ha.automatic-failover.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.cached-dfsused.check.interval.ms</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.identifierFactory</name><value>datanucleus1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.http.policy</name><value>HTTP_ONLY</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.persist.jobstatus.hours</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.blockreport.intervalMsec</name><value>21600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.hashtable.initialCapacity</name><value>100000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.lifeline.handler.ratio</name><value>0.10</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.seqfile.compress.blocksize</name><value>1000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.hybridgrace.hashtable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.admin.address</name><value>ip-10-11-21-11.alationdata.com:8141</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.failover.connection.retries.on.timeouts</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.rm.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.zookeeper.session-timeout.ms</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.checksum.algo.impl</name><value>org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.replication.max</name><value>50</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container-manager.thread-count</name><value>20</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.groups.negative-cache.secs</name><value>30</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.impl</name><value>org.apache.hadoop.fs.s3a.S3AFileSystem</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.jdbcdriver</name><value>org.apache.derby.jdbc.EmbeddedDriver</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.zk.retry.times</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.event.expiry.duration</name><value>0s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.merge.tezfiles</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>file.stream-buffer-size</name><value>4096</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.add.raw.reserved.namespace</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping</name><value>org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.files.visibilities</name><value>false,false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.recovery.store.fs.uri</name><value>/tmp/hadoop-hive/mapred/history/recoverystore</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.default.chunk.view.size</name><value>32768</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.application.attempt.id</name><value>1</value><source>programatically</source></property>
<property><name>yarn.resourcemanager.scheduler.monitor.policies</name><value>org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.cbo.returnpath.hiveop</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.keytab</name><value>/etc/krb5.keytab</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.zookeeper.namespace</name><value>hive_zookeeper_namespace</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.ppd</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.transactional.table.scan</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.schema.autoCreateAll</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.input.buffer.percent</name><value>0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.app-cache-size</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.address</name><value>ip-10-11-21-11.alationdata.com:10020</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.seqfile.sorter.recordlimit</name><value>1000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.num.checkpoints.retained</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.workflow.name</name><value>INSERT INTO otherthings (id, stuff_id) VALUES (2, 1)</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.max.split.locations</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.local.dir.minspacestart</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.enable.memory.manager</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.log.level</name><value>INFO</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.webapp.address</name><value>ip-10-11-21-11.alationdata.com:8188</value><source>programatically</source><source>job.xml</source></property>
<property><name>output.formatter</name><value>org.apache.hadoop.hive.ql.exec.FetchFormatter$ThriftFormatter</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.autogen.columnalias.prefix.includefuncname</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.jdbc.timeout</name><value>30s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.hybridgrace.minwbsize</name><value>524288</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.null.scan</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.zk-retry-interval-ms</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.groups.cache.background.reload.threads</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.workaround.non.threadsafe.getpwuid</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapred.child.java.opts</name><value>-Xmx200m</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.read.shortcircuit.streams.cache.expiry.ms</name><value>300000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.direct.sql.max.query.length</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.dns.log-slow-lookups.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.crypto.codec.classes.aes.ctr.nopadding</name><value>org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.default.serde</name><value>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.querylog.plan.progress.interval</name><value>60000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.progress.timeout</name><value>0s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.end-notification.retry.interval</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.socket.connect-timeout</name><value>60s</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.log.level</name><value>INFO</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.retain-seconds</name><value>604800</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.remote-app-log-dir</name><value>/app-logs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.cross-origin.allowed-headers</name><value>X-Requested-With,Content-Type,Accept,Origin</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.input.format</name><value>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server.read.socket.timeout</name><value>10s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.tasktracker.maxblacklists</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.directory.search.timeout</name><value>10000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.cross-origin.allowed-methods</name><value>GET,POST,HEAD</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.decommission.interval</name><value>30</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.typecheck.on.insert</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.submithostname</name><value>ip-10-11-21-11.alationdata.com</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs</name><value>86400</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.history.retention.failed</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.insert.into.external.tables</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.delete.debug-delay-sec</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.https-address</name><value>ip-10-11-21-11.alationdata.com:50470</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.collect.rawdatasize</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.scheduler.capacity.ordering-policy.priority-utilization.underutilized-preemption.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.rest-csrf.methods-to-ignore</name><value>GET,OPTIONS,HEAD,TRACE</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.service.metrics.file.frequency</name><value>5s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.webinterface.trusted</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.local.dir.minspacekill</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.enforce.bucketing</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.azure.authorization</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.cross-origin.max-age</name><value>1800</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.output.key.class</name><value>org.apache.hadoop.io.Text</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.https.server.keystore.resource</name><value>ssl-server.xml</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log-aggregation.compression-type</name><value>gz</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.hosts.exclude</name><value>/etc/hadoop/conf/dfs.exclude</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.http.address</name><value>0.0.0.0:50060</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.convert.sortmerge.join.to.mapjoin</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.connect.timeout</name><value>20000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.insert.into.multilevel.dirs</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>datanucleus.transactionIsolation</name><value>read-committed</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metadata.move.exported.metadata.to.trash</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.path.based.cache.block.map.allocation.percent</name><value>0.25</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.cross-origin.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>output.protocol</name><value>7</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.https.port</name><value>50470</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.cluster.temp.dir</name><value>/tmp/hadoop-hive/mapred/temp</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.output.fileoutputformat.compress</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.max-lock-hold-to-release-lease-ms</name><value>25</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.client.failover-retries-on-socket-timeouts</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.client.socket.lifetime</name><value>0s</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.buffer.dir</name><value>/tmp/hadoop-hive/s3a</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.block.write.replace-datanode-on-failure.best-effort</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.aux-services.spark2_shuffle.class</name><value>org.apache.spark.network.yarn.YarnShuffleService</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.fetch.task.aggr</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.dynamic.partition.pruning.max.event.size</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.reducededuplication.min.reducer</name><value>4</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.port</name><value>9083</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.kerberos.keytab</name><value>/home/hive/hadoop.keytab</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.metrics.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.ping.interval</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.nm.uploader.thread-count</name><value>20</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.compactor.history.retention.succeeded</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.http.max.idle.time</name><value>1800s</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.test.mode</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.auto.convert.sortmerge.join.reduce.side</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.admin.address</name><value>0.0.0.0:10033</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.pmem-check-enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.user.install.directory</name><value>/user/</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.webapp.rest-csrf.custom-header</name><value>X-XSRF-Header</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.max.dynamic.partitions</name><value>5000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.java.opts</name><value>-Xmx756m</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.repl.rootdir</name><value>/user/hive/repl/</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.fast.upload</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.entity-group-fs-store.active-dir</name><value>/ats/active/</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.docker-container-executor.exec-name</name><value>/usr/bin/docker</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold</name><value>10737418240</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.ppd.remove.duplicatefilters</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.direct.sql.max.elements.values.clause</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.sharedcache.admin.address</name><value>0.0.0.0:8047</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.session.id</name><value>f9f9016f-5d22-4202-bfec-0ab6e2519f06</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.handler.count</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.cached.conn.retry</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.union.remove</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.test.authz.sstd.hs2.mode</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.jobhistory.block.size</name><value>3145728</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.orc.cache.stripe.details.mem.size</name><value>268435456</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.readahead.range</name><value>64K</value><source>programatically</source><source>job.xml</source></property>
<property><name>javax.jdo.option.ConnectionPassword</name><value>HIVE</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3.sleepTimeSeconds</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.log-aggregation.file-controller.IndexedFormat.class</name><value>org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.du.reserved</name><value>1073741824</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.zk.retry.ceiling.ms</name><value>60000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.address</name><value>0.0.0.0:50010</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.client.server.connect.timeout</name><value>90000ms</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.lock.numretries</name><value>100</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.num.extra.edits.retained</name><value>1000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.security.authorization.task.factory</name><value>org.apache.hadoop.hive.ql.parse.authorization.HiveAuthorizationTaskFactoryImpl</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.admin.acl</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.drop.cache.behind.reads</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.files.timestamps</name><value>1544815913224,1544815913334</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.ping</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.error.on.empty.partition</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapper.cannot.span.multiple.partitions</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.directoryscan.interval</name><value>21600</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.reducers.max</name><value>1009</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.fileinputformat.split.maxsize</name><value>256000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.archive.intermediate.extracted</name><value>_INTERMEDIATE_EXTRACTED</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.script.operator.id.env.var</name><value>HIVE_SCRIPT_OPERATOR_ID</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.ha.automatic-failover.zk-base-path</name><value>/yarn-leader-election</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.hs2.user.access</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3native.replication</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.retrycache.expirytime.millis</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.spark.client.rpc.max.size</name><value>52428800</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.webapp.rest-csrf.methods-to-ignore</name><value>GET,OPTIONS,HEAD</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.connection.maximum</name><value>15</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.limit.optimize.enable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.session.silent</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.server.tcpnodelay</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.client.job.max-retries</name><value>60</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.expression.proxy</name><value>org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.timeline-service.client.internal-timers-ttl-secs</name><value>420</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.orc.cache.use.soft.references</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.dbclass</name><value>fs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.log.level</name><value>INFO</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.webapp.rest-csrf.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.thrift.worker.keepalive.time</name><value>60s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.speculative-cap-running-tasks</name><value>0.1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.hdfs-servers</name><value>hdfs://ip-10-11-21-11.alationdata.com:8020</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.multipart.purge.age</name><value>86400</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.jobhistory.lru.cache.size</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.use.legacy.blockreader.local</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.sync.behind.writes</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.failover.sleep.base.millis</name><value>500</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.fetch.retry.timeout-ms</name><value>30000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.autogen.columnalias.prefix.label</name><value>_c</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.data.dir.perm</name><value>750</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.mapjoin.optimized.hashtable</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.lock.sleep.between.retries</name><value>60s</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.fileoutputcommitter.algorithm.version</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.client.drop.partitions.using.expressions</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.exec.submit.local.task.via.child</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.datanode-restart.timeout</name><value>30</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.metastore.aggregate.stats.cache.enabled</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.hdfs.configuration.version</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.stats.retries.max</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.server.listen.queue.size</name><value>128</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.ssl.file.buffer.size</name><value>65536</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3a.multipart.purge</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.prewarm.numcontainers</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.hdfs-blocks-metadata.enabled</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.zookeeper.publish.configs</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.runtime.linux.docker.default-container-network</name><value>host</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.explain.dependency.append.tasktype</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.async.exec.shutdown.timeout</name><value>10s</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.dispatcher.drain-events.timeout</name><value>300000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.runtime.linux.docker.capabilities</name><value>CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.test.fail.heartbeater</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.idle.operation.timeout</name><value>5d</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.archives.filesizes</name><value>216074021</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.sampling.orderby.number</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source></property>
<property><name>dfs.namenode.fs-limits.max-directory-items</name><value>1048576</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log.retain-seconds</name><value>604800</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.image.transfer.chunksize</name><value>65536</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.optimize.bucketmapjoin.sortedmerge</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.direct.sql.max.elements.in.clause</name><value>1000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.map.aggr</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.fetch.task.conversion.threshold</name><value>1073741824</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.du.interval</name><value>600000</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.file-block-storage-locations.num-threads</name><value>10</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.markreset.buffer.percent</name><value>0.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.connection-keep-alive.timeout</name><value>5</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.tez.task.scale.memory.reserve.fraction.max</name><value>0.5</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.security.kms.client.encrypted.key.cache.size</name><value>500</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.server2.map.fair.scheduler.queue</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.txn.manager</name><value>org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.cluster.administrators</name><value> hdfs</value><source>programatically</source><source>job.xml</source></property>
<property><name>hive.allow.udf.load.on.demand</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.registry.zk.root</name><value>/registry</value><source>programatically</source><source>job.xml</source></property>
<property><name>s3.stream-buffer-size</name><value>4096</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.client.job.retry-interval</name><value>2000</value><source>programatically</source><source>job.xml</source></property>
</configuration>